{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c9c97e-20bb-45d2-96d3-100437094f57",
   "metadata": {},
   "source": [
    "### Training a Custom Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ffc94d-fce5-4f65-91bd-f9c7719c6cf7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6535b7-6d97-4691-b5bd-b752740a1e5b",
   "metadata": {},
   "source": [
    "## Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c142e6-16d3-47d8-855e-970acc319f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gathanasiou/oxcitas/projects/ML/MRI/deepMRI/deepMRI_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f58306e-1edb-45a8-b7bd-52deb4df83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory of `src` to the Python path\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1aad589-f9e3-4377-a8b5-01798a54585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports (placeholders for demonstration)\n",
    "import src.constants as C\n",
    "from src.data import Dataset\n",
    "from src.models import Custom3DCNN, SFCN, resnet18\n",
    "from src.utils import AWDLoss, KLDivLoss, LocalMAE, augment, scheduler, discretize_ages, save_subject_ids, load_scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea99e76-6575-48f8-8a37-f8118f89dff5",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Setting up constants and a small demonstration configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65ab7fb6-8eba-457e-8ffd-381a2753e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for demonstration\n",
    "CSIZE = 128  # Reduced size for faster processing\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "BINS = 10\n",
    "USE_SOFT_LABELS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1282070-bb9e-4d32-9b3b-23be3631e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training configuration\n",
    "config_path = Path('../configs/training_config.json').expanduser().resolve()\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca069d7a-5c6d-42ca-afbd-472a8198d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepMRI@demo\n",
      "/Users/gathanasiou/oxcitas/UKB-gen-clocks/DL-apporach/configs/dataset_configs\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Extract configuration parameters\n",
    "PROJECT_NAME = config['project_name']\n",
    "OUTPUT_DIRECTORY = Path(config['output_directory']).expanduser().resolve()\n",
    "USE_SOFT_LABELS = config['use_soft_labels']\n",
    "print(PROJECT_NAME) \n",
    "print(OUTPUT_DIRECTORY) \n",
    "print(USE_SOFT_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c6276-5655-4210-8ce9-96fdffd1a34d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f050d5af-8059-4c64-bce1-709ac018483c",
   "metadata": {},
   "source": [
    "## Back up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5de1fbb-a61d-4037-8097-1758e2a95318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "    \"\"\"\n",
    "    Prepare the dataset by appending file extensions to scan IDs.\n",
    "    \"\"\"\n",
    "    dataset.scanIDs = [scan + '.mgz' for scan in dataset.scanIDs]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6a1ba4f-fa35-4cdf-8a4b-bdc9a1fab764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_batches(X_train, y_train, X_test, y_test, batch_size, soft_labels=False):\n",
    "    \"\"\"\n",
    "    Create TensorFlow data batches for training and testing.\n",
    "    \"\"\"\n",
    "    if soft_labels:\n",
    "        train_labels = np.array([item for item in y_train])\n",
    "        test_labels = np.array([item for item in y_test])\n",
    "    else:\n",
    "        train_labels = np.array(y_train)\n",
    "        test_labels = np.array(y_test)\n",
    "\n",
    "    train_scans = tf.data.Dataset.from_tensor_slices((X_train, train_labels))\n",
    "    test_scans = tf.data.Dataset.from_tensor_slices((X_test, test_labels))\n",
    "\n",
    "    train_scans = train_scans.map(load_scan, num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "    test_scans = test_scans.map(load_scan, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    BUFFER_SIZE = 500\n",
    "    train_batches = (\n",
    "        train_scans\n",
    "        .cache()\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .filter(lambda x, y: tf.shape(x)[0] > 1)  # Filter out small batches\n",
    "        .repeat()\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    test_batches = test_scans.batch(batch_size).filter(lambda x, y: tf.shape(x)[0] > 1)  # Filter out small batches\n",
    "\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9979b639-117f-4192-baea-04e314d7da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_real_labels(model, learning_rate):\n",
    "    \"\"\"\n",
    "    Compile the model for real labels with the custom AWD loss function and Adam optimizer.\n",
    "    \"\"\"\n",
    "    awdLoss = AWDLoss(num_bins=C.BINS, initial_alpha=C.ALPHA, initial_beta=C.BETA)\n",
    "    \n",
    "    def awd_loss(y_true, y_pred):\n",
    "        return awdLoss(y_true, y_pred)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=awd_loss,\n",
    "                  metrics=['mean_absolute_error', 'mean_squared_error', LocalMAE(num_bins=C.BINS)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c8f0d-7963-41c2-a16c-81e0335e1a42",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Loading real data based on the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ae8885-3033-48a6-9044-89025435417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Target path:  ../configs/targets/real_targets.json\n"
     ]
    }
   ],
   "source": [
    "# Load dataset configuration\n",
    "DATASET_CONFIG_PATH = OUTPUT_DIRECTORY / ('dataset_config_soft.json' if USE_SOFT_LABELS else 'dataset_config_real.json')\n",
    "data = Dataset.from_file(DATASET_CONFIG_PATH)\n",
    "data = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98991617-494b-49df-bfc6-7b5b0cbfe471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.TEST_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce742089-8a23-4abf-abb3-bec8ace6bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects: 9\n",
      "Training subjects: 8, Test subjects: 1\n",
      "Train Scans: 9, Train Labels: 9\n",
      "Test Scans: 1, Test Labels: 1\n",
      "Formatted Train Labels Shape: (9,), Test Labels Shape: (1,)\n",
      "Training fold 1...\n",
      "Number of cases in X_train: 9\n",
      "Number of cases in X_test: 1\n"
     ]
    }
   ],
   "source": [
    "# Prepare train-test splits\n",
    "for fold_num, (X_train, X_test, y_train, y_test) in enumerate(data.train_test_subjID_iterator(), 1):\n",
    "    print(f\"Training fold {fold_num}...\")\n",
    "    print(f\"Number of cases in X_train: {len(X_train)}\")\n",
    "    print(f\"Number of cases in X_test: {len(X_test)}\")\n",
    "\n",
    "    train_batches, test_batches = create_data_batches(X_train, y_train, X_test, y_test, BATCH_SIZE, soft_labels=USE_SOFT_LABELS)\n",
    "    break  # Only load the first fold for this demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fde343d1-453b-49fe-8254-e5577f51fb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects: 9\n",
      "Training subjects: 8, Test subjects: 1\n",
      "Train Scans: 9, Train Labels: 9\n",
      "Test Scans: 1, Test Labels: 1\n",
      "Formatted Train Labels Shape: (9,), Test Labels Shape: (1,)\n",
      "Training fold 1...\n",
      "Number of cases in X_train: 9\n",
      "Number of cases in X_test: 1\n",
      "Regression case initialized...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'ResourceVariable' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 61\u001b[0m\n\u001b[1;32m     57\u001b[0m save_subject_ids(checkpoint_dir_fold, fold_num, X_train, X_test)\n\u001b[1;32m     59\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [checkpoint, lr_scheduler]\n\u001b[0;32m---> 61\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oxcitas/projects/ML/MRI/deepMRI/deepMRI_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m, in \u001b[0;36mcompile_model_real_labels.<locals>.awd_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mawd_loss\u001b[39m(y_true, y_pred):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mawdLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oxcitas/UKB-gen-clocks/DL-apporach/src/utils.py:133\u001b[0m, in \u001b[0;36mAWDLoss.__call__\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    131\u001b[0m _, maes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mwhile_loop(\u001b[38;5;28;01mlambda\u001b[39;00m i, _: i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins, calculate_bin_mae, [\u001b[38;5;241m0\u001b[39m, maes])\n\u001b[1;32m    132\u001b[0m maes \u001b[38;5;241m=\u001b[39m maes\u001b[38;5;241m.\u001b[39mstack()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_coeffs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(maes):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight coefficients (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_coeffs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) do not match number of MAE bins (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(maes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m weighted_maes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_coeffs \u001b[38;5;241m*\u001b[39m maes)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ResourceVariable' has no len()"
     ]
    }
   ],
   "source": [
    "for fold_num, (X_train, X_test, y_train, y_test) in enumerate(data.train_test_subjID_iterator(), 1):\n",
    "    print(f\"Training fold {fold_num}...\")\n",
    "    print(f\"Number of cases in X_train: {len(X_train)}\")\n",
    "    print(f\"Number of cases in X_test: {len(X_test)}\")\n",
    "\n",
    "    # y_train_bins, train_bins = discretize_ages(y_train)\n",
    "    # y_test_bins, test_bins = discretize_ages(y_test)\n",
    "\n",
    "    model_pick = C.RESNET\n",
    "    if USE_SOFT_LABELS:\n",
    "        print(\"Soft labeling case initialized...\")\n",
    "        if model_pick:\n",
    "            print(\"Using ResNet model...\")\n",
    "            model = resnet18(input_shape=(C.CSIZE, C.CSIZE, C.CSIZE, 1),\n",
    "                     num_classes=int((C.HGH_BIN - C.LOW_BIN) / C.STEP_BIN), \n",
    "                     channel_size=[64, 64, 128, 256, 512], \n",
    "                     dropout=True)\n",
    "        else:\n",
    "            print(\"Using SFCN model...\")\n",
    "            model = SFCN(input_shape=(C.CSIZE, C.CSIZE, C.CSIZE, 1), \n",
    "                        channels=[32, 64, 128, 256, 256, 64], \n",
    "                        output_dim=int((C.HGH_BIN - C.LOW_BIN) / C.STEP_BIN), \n",
    "                        use_dropout=True, \n",
    "                        csize=C.CSIZE).build_model()\n",
    "        model = compile_model_soft_labels(model, C.LEARNING_RATE)\n",
    "        train_batches, test_batches = create_data_batches(X_train, y_train, X_test, y_test, C.BATCH_SIZE, soft_labels=True)\n",
    "    else:\n",
    "        print(\"Regression case initialized...\")\n",
    "        model = Custom3DCNN(input_shape=(C.CSIZE, C.CSIZE, C.CSIZE, 1),\n",
    "                            depth=C.DEPTH, \n",
    "                            initial_filters=C.INITIAL_FILTERS, \n",
    "                            l2_strength=C.L2_STRENGTH).build_model()\n",
    "        model = compile_model_real_labels(model, C.LEARNING_RATE)\n",
    "        train_batches, test_batches = create_data_batches(X_train, y_train, X_test, y_test, C.BATCH_SIZE)\n",
    "\n",
    "    STEPS_PER_EPOCH = len(X_train) // C.BATCH_SIZE\n",
    "    checkpoint_dir_fold = os.path.join('../data/', f\"model_output/fold_{fold_num}\")\n",
    "    os.makedirs(checkpoint_dir_fold, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir_fold, f\"best_weights_fold_{fold_num}.weights.h5\")\n",
    "\n",
    "    if C.LOAD_WEIGHTS and os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from {checkpoint_path}...\")\n",
    "        model.load_weights(checkpoint_path)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                 save_weights_only=True,\n",
    "                                 monitor='val_loss',\n",
    "                                 mode='min',\n",
    "                                 save_best_only=True,\n",
    "                                 verbose=1)\n",
    "    \n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "    log_file_path = os.path.join('../data/', 'logs', f'metrics_log_fold_{fold_num}.txt')\n",
    "    os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "    \n",
    "    save_subject_ids(checkpoint_dir_fold, fold_num, X_train, X_test)\n",
    "\n",
    "    callbacks = [checkpoint, lr_scheduler]\n",
    "\n",
    "    history = model.fit(train_batches,\n",
    "                        epochs=C.EPOCHS,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        validation_data=test_batches,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee459867-7da5-4e89-aa2e-b4db747280c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1a43f-56d9-4cf9-9f95-eb32a7d9c804",
   "metadata": {},
   "source": [
    "## Model Compilation\n",
    "Compiling a model for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49e8d764-48a7-4dbe-8326-a079bb80d6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real labels...\n"
     ]
    }
   ],
   "source": [
    "# Model selection and compilation\n",
    "if USE_SOFT_LABELS:\n",
    "    print(\"Using soft labels...\")\n",
    "    model = resnet18(input_shape=(CSIZE, CSIZE, CSIZE, 1),\n",
    "                     num_classes=BINS,\n",
    "                     channel_size=[64, 64, 128, 256, 512],\n",
    "                     dropout=True)\n",
    "    model = compile_model_soft_labels(model, LEARNING_RATE)\n",
    "else:\n",
    "    print(\"Using real labels...\")\n",
    "    model = Custom3DCNN(input_shape=(CSIZE, CSIZE, CSIZE, 1), depth=3, initial_filters=32, l2_strength=0.01).build_model()\n",
    "    model = compile_model_real_labels(model, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d7583-5a7e-4174-8e1a-800fe68dc4b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388f7353-95bd-4e16-bb50-b52606b4a83e",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Training the model on a small dataset for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23ffa342-9609-4321-85ba-59cd0b818138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for training\n",
    "checkpoint_path = OUTPUT_DIRECTORY / \"best_model.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdbe2fab-7ff8-4c65-acd1-f30419b71148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps per epoch\n",
    "STEPS_PER_EPOCH = len(X_train) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aad13094-8326-429a-b09f-a19c91525128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'ResourceVariable' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oxcitas/projects/ML/MRI/deepMRI/deepMRI_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m, in \u001b[0;36mcompile_model_real_labels.<locals>.awd_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mawd_loss\u001b[39m(y_true, y_pred):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mawdLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oxcitas/UKB-gen-clocks/DL-apporach/src/utils.py:133\u001b[0m, in \u001b[0;36mAWDLoss.__call__\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    131\u001b[0m _, maes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mwhile_loop(\u001b[38;5;28;01mlambda\u001b[39;00m i, _: i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins, calculate_bin_mae, [\u001b[38;5;241m0\u001b[39m, maes])\n\u001b[1;32m    132\u001b[0m maes \u001b[38;5;241m=\u001b[39m maes\u001b[38;5;241m.\u001b[39mstack()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_coeffs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(maes):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight coefficients (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_coeffs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) do not match number of MAE bins (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(maes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m weighted_maes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_coeffs \u001b[38;5;241m*\u001b[39m maes)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ResourceVariable' has no len()"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_batches,\n",
    "                    validation_data=test_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    callbacks=[checkpoint, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340b87c-947f-4a8f-8fbc-4885956dd305",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62cbae-7501-4cb3-83f1-8a08ea034ef3",
   "metadata": {},
   "source": [
    "## Evaluation and Predictions\n",
    "Evaluate the trained model and demonstrate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3126617-bac8-4b5a-8da5-18d4d94653da",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ResourceVariable' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, mae, mse \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Results - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/oxcitas/projects/ML/MRI/deepMRI/deepMRI_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m, in \u001b[0;36mawd_loss_fn\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mawd_loss_fn\u001b[39m(y_true, y_pred):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mawd_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oxcitas/UKB-gen-clocks/DL-apporach/src/utils.py:133\u001b[0m, in \u001b[0;36mAWDLoss.__call__\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    131\u001b[0m _, maes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mwhile_loop(\u001b[38;5;28;01mlambda\u001b[39;00m i, _: i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins, calculate_bin_mae, [\u001b[38;5;241m0\u001b[39m, maes])\n\u001b[1;32m    132\u001b[0m maes \u001b[38;5;241m=\u001b[39m maes\u001b[38;5;241m.\u001b[39mstack()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_coeffs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(maes):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight coefficients (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_coeffs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) do not match number of MAE bins (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(maes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m weighted_maes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_coeffs \u001b[38;5;241m*\u001b[39m maes)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ResourceVariable' has no len()"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, mae, mse = model.evaluate(test_dataset)\n",
    "print(f\"Evaluation Results - Loss: {loss}, MAE: {mae}, MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7cf932d-3501-4785-aae7-994be02c9e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step\n",
      "Sample Predictions: [[-0.04665842]\n",
      " [-0.04773519]\n",
      " [-0.04873811]\n",
      " [-0.04604891]\n",
      " [-0.04694086]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(test_dataset)\n",
    "print(f\"Sample Predictions: {predictions[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5439ec1-8580-4799-9fa2-2a06aeb9a023",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8943d6-45c5-48f3-b651-413eadaf67a3",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Visualize augmentation and training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbb8dee0-46e3-449a-8ce8-fdb13dd80fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa92b7d-14a4-427f-a5bd-a2037ecee798",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'augmented_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot augmentation example\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43maugmented_sample\u001b[49m[:, :, CSIZE \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Visualize the middle slice\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAugmented Sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'augmented_sample' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot augmentation example\n",
    "plt.figure()\n",
    "plt.imshow(augmented_sample[:, :, CSIZE // 2, 0], cmap=\"gray\")  # Visualize the middle slice\n",
    "plt.title(\"Augmented Sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23cbbf09-ca81-4318-8104-b5a70cfcdc83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining History\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training history\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Training History\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f33fce-6e3e-4656-a624-75375415b4c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af9b1f-810d-4ce4-a4f4-28072022ef87",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrates a simplified training pipeline using synthetic data. Adapt this template with real data and models for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28088933-2fb0-4701-b96f-0ce1e8617a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
